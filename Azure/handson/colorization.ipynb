{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --list /opt/intel/openvino/inference_engine/demos/python_demos/colorization_demo/models.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /opt/intel/openvino/deployment_tools/tools/model_downloader/converter.py --name colorization-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IECore\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from argparse import ArgumentParser, SUPPRESS\n",
    "import logging as log\n",
    "import sys\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import IPython.display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def infer_video(video_path):\n",
    "    #args = build_arg().parse_args()\n",
    "    #coeffs = args.coeffs\n",
    "    coeffs = \"public/colorization-v2/colorization-v2.npy\"\n",
    "\n",
    "    # mean is stored in the source caffe model and passed to IR\n",
    "    verbose = False\n",
    "    log.basicConfig(format=\"[ %(levelname)s ] %(message)s\",\n",
    "                    level=log.INFO if not verbose else log.DEBUG, stream=sys.stdout)\n",
    "\n",
    "    log.debug(\"Load network\")\n",
    "    ie = IECore()\n",
    "    model_path = \"public/colorization-v2/FP32/colorization-v2.xml\"\n",
    "    load_net = ie.read_network(model_path, os.path.splitext(model_path)[0] + \".bin\")\n",
    "    load_net.batch_size = 1\n",
    "    exec_net = ie.load_network(network=load_net, device_name=\"CPU\")\n",
    "\n",
    "    assert len(load_net.inputs) == 1, \"Expected number of inputs is equal 1\"\n",
    "    input_blob = next(iter(load_net.inputs))\n",
    "    input_shape = load_net.inputs[input_blob].shape\n",
    "    assert input_shape[1] == 1, \"Expected model input shape with 1 channel\"\n",
    "\n",
    "    assert len(load_net.outputs) == 1, \"Expected number of outputs is equal 1\"\n",
    "    output_blob = next(iter(load_net.outputs))\n",
    "    output_shape = load_net.outputs[output_blob].shape\n",
    "    assert output_shape == [1, 313, 56, 56], \"Shape of outputs does not match network shape outputs\"\n",
    "\n",
    "    _, _, h_in, w_in = input_shape\n",
    "\n",
    "    input_path = video_path\n",
    "    try:\n",
    "        input_source = int(input_path)\n",
    "    except ValueError:\n",
    "        input_source = input_path\n",
    "\n",
    "    cap = cv.VideoCapture(input_source)\n",
    "    if not cap.isOpened():\n",
    "        assert \"{} not exist\".format(input_source)\n",
    "\n",
    "    color_coeff = np.load(coeffs).astype(np.float32)\n",
    "    assert color_coeff.shape == (313, 2), \"Current shape of color coefficients does not match required shape\"\n",
    "\n",
    "    while True:\n",
    "        log.debug(\"#############################\")\n",
    "        hasFrame, original_frame = cap.read()\n",
    "        if not hasFrame:\n",
    "            break\n",
    "        (h_orig, w_orig) = original_frame.shape[:2]\n",
    "\n",
    "        log.debug(\"Preprocessing frame\")\n",
    "        if original_frame.shape[2] > 1:\n",
    "            frame = cv.cvtColor(cv.cvtColor(original_frame, cv.COLOR_BGR2GRAY), cv.COLOR_GRAY2RGB)\n",
    "        else:\n",
    "            frame = cv.cvtColor(original_frame, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "        img_rgb = frame.astype(np.float32) / 255\n",
    "        img_lab = cv.cvtColor(img_rgb, cv.COLOR_RGB2Lab)\n",
    "        img_l_rs = cv.resize(img_lab.copy(), (w_in, h_in))[:, :, 0]\n",
    "\n",
    "        log.debug(\"Network inference\")\n",
    "        res = exec_net.infer(inputs={input_blob: [img_l_rs]})\n",
    "\n",
    "        update_res = (res[output_blob] * color_coeff.transpose()[:, :, np.newaxis, np.newaxis]).sum(1)\n",
    "\n",
    "        log.debug(\"Get results\")\n",
    "        out = update_res.transpose((1, 2, 0))\n",
    "        out = cv.resize(out, (w_orig, h_orig))\n",
    "        img_lab_out = np.concatenate((img_lab[:, :, 0][:, :, np.newaxis], out), axis=2)\n",
    "        img_bgr_out = np.clip(cv.cvtColor(img_lab_out, cv.COLOR_Lab2BGR), 0, 1)\n",
    "\n",
    "        no_show = False\n",
    "        if not no_show:\n",
    "            log.debug(\"Show results\")\n",
    "            imshowSize = (320, 240)\n",
    "            original_image = cv.resize(original_frame, imshowSize)\n",
    "            grayscale_image = cv.resize(frame, imshowSize)\n",
    "            colorize_image = (cv.resize(img_bgr_out, imshowSize) * 255).astype(np.uint8)\n",
    "            lab_image = (cv.resize(img_lab_out, imshowSize)).astype(np.uint8)\n",
    "\n",
    "            original_image = cv.putText(original_image, 'Original', (25, 50),\n",
    "                                        cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "            grayscale_image = cv.putText(grayscale_image, 'Grayscale', (25, 50),\n",
    "                                        cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "            colorize_image = cv.putText(colorize_image, 'Colorize', (25, 50),\n",
    "                                        cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "            lab_image = cv.putText(lab_image, 'LAB interpetation', (25, 50),\n",
    "                                   cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "            #ir_image = [cv.hconcat([original_image, grayscale_image]),\n",
    "            #            cv.hconcat([lab_image, colorize_image])]\n",
    "            ir_image = [cv.hconcat([original_image, colorize_image])]\n",
    "            final_image = cv.vconcat(ir_image)\n",
    "            final_image = cv.cvtColor(final_image, cv.COLOR_BGR2RGB)\n",
    "            #cv.imshow('Colorization Demo', final_image)\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            f = io.BytesIO()\n",
    "            PIL.Image.fromarray(final_image).save(f, 'jpeg')\n",
    "            IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "        \n",
    "            if not cv.waitKey(1) < 0:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_video(\"bw.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
