{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.サンプル学習データのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://hiouchiystorage.blob.core.windows.net/share/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv data.zip train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip train_data/data.zip -d train_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.モデルの学習（MobileNet v1を転移学習）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "from tensorflow.keras import optimizers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'train_data/test/'\n",
    "train_path = 'train_data/train/'\n",
    "val_path = 'train_data/val/'\n",
    "WIDTH=224\n",
    "HEIGHT=224\n",
    "BATCH_SIZE=64\n",
    "\n",
    "#Train DataSet Generator with Augmentation\n",
    "print(\"\\nTraining Data Set\")\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_flow = train_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Validation DataSet Generator with Augmentation\n",
    "print(\"\\nValidation Data Set\")\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_flow = val_generator.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Test DataSet Generator with Augmentation\n",
    "print(\"\\nTest Data Set\")\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_flow = test_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize MobileNet with transfer learning\n",
    "base_model = applications.MobileNet(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(WIDTH, HEIGHT,3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# and a dense layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_flow.class_indices), activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional MobileNet layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "import math\n",
    "top_layers_file_path=\"mobilenet.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('./logs/mn-log.csv', append=True)\n",
    "\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=1, \n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])\n",
    "\n",
    "\n",
    "model.load_weights(top_layers_file_path)\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)\n",
    "\n",
    "\n",
    "label = [k for k,v in train_flow.class_indices.items()]\n",
    "with open('labels.txt', 'w+') as file:\n",
    "    file.write(\"\\n\".join(label))\n",
    " \n",
    "tf.saved_model.save(model, 'mobilenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.モデルの推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import argparse\n",
    "import sys\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load('saved_model')\n",
    "#print(list(loaded.signatures.keys()))  # [\"serving_default\"]\n",
    "\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "output_node_name = next(iter(infer.structured_outputs.keys()))\n",
    "\n",
    "#Read in Labels\n",
    "arg_labels=\"labels.txt\"\n",
    "label_file = open(arg_labels, \"r\")\n",
    "labels = label_file.read().split('\\n')\n",
    "\n",
    "file_list = glob.glob(\"train_data/test/*/*\")\n",
    "for i in range(50):\n",
    "    img_path = random.choice(file_list)\n",
    "    img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "    \n",
    "    start1 = time.time()\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=[224, 224])\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    x = tf.keras.applications.mobilenet.preprocess_input(x[tf.newaxis,...])\n",
    "\n",
    "    start2 = time.time() #ここ追加\n",
    "    labeling = infer(tf.constant(x))[output_node_name]\n",
    "    infer_time = time.time() - start2\n",
    "    total_time = time.time() - start1\n",
    "    print(\"Filename:{}, Prediction:{}, ProcTime:{}, InferTime:{}\".format(img_path, labels[np.argsort(labeling)[0,::-1][0]], int(total_time*1000), int(infer_time*1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowでの作業は以上となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ここからOpenVINO↓\n",
    "# 4.OpenVINOでFP32モデルをCPUに最適化（IRに変換）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからはIntel® OpenVINO™ Toolkitを用いた量子化方法をご紹介します。\n",
    "\n",
    "といってもまずは、元のTensorFlowのモデル（FP32）をOpenVINOのIR（Intermidiate Repretation）形式に変換するところから実施しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --saved_model_dir ./saved_model --input_shape=[1,224,224,3] --data_type FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IR(xml+bin)が生成されていることを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.最適化済みのモデルをOpenVINOの推論エンジン（Inference Engine）上で実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import argparse\n",
    "import sys\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.labels = []\n",
    "        labels_filename = \"labels.txt\"\n",
    "        #Read in Labels\n",
    "        arg_labels=\"labels.txt\"\n",
    "        label_file = open(arg_labels, \"r\")\n",
    "        self.labels = label_file.read().split('\\n')\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def convert_to_opencv(self, image):\n",
    "        # RGB -> BGR conversion is performed as well.\n",
    "        image = image.convert('RGB')\n",
    "        r,g,b = np.array(image).T\n",
    "        opencv_image = np.array([b,g,r]).transpose()\n",
    "        return opencv_image\n",
    "\n",
    "    def crop_center(self, img,cropx,cropy):\n",
    "        h, w = img.shape[:2]\n",
    "        startx = w//2-(cropx//2)\n",
    "        starty = h//2-(cropy//2)\n",
    "        return img[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "    def resize_down_to_1600_max_dim(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if (h < 1600 and w < 1600):\n",
    "            return image\n",
    "\n",
    "        new_size = (1600 * w // h, 1600) if (h > w) else (1600, 1600 * h // w)\n",
    "        return cv2.resize(image, new_size, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    def resize_to_256_square(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        return cv2.resize(image, (256, 256), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    def update_orientation(self, image):\n",
    "        exif_orientation_tag = 0x0112\n",
    "        if hasattr(image, '_getexif'):\n",
    "            exif = image._getexif()\n",
    "            if (exif != None and exif_orientation_tag in exif):\n",
    "                orientation = exif.get(exif_orientation_tag, 1)\n",
    "                # orientation is 1 based, shift to zero based and flip/transpose based on 0-based values\n",
    "                orientation -= 1\n",
    "                if orientation >= 4:\n",
    "                    image = image.transpose(Image.TRANSPOSE)\n",
    "                if orientation == 2 or orientation == 3 or orientation == 6 or orientation == 7:\n",
    "                    image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                if orientation == 1 or orientation == 2 or orientation == 5 or orientation == 6:\n",
    "                    image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return image\n",
    "\n",
    "class OpenVINOModel(Model):\n",
    "\n",
    "    def __init__(self, target_device, modelFilePath):\n",
    "        super(OpenVINOModel, self).__init__()\n",
    "\n",
    "        # These are set to the default names from exported models, update as needed.\n",
    "        model_xml = modelFilePath\n",
    "        model_bin = modelFilePath.replace('.xml', '.bin')\n",
    "\n",
    "        # Plugin initialization for specified device and load extensions library if specified\n",
    "        # Set the desired device name as 'device' parameter. This sample support these 3 names: CPU, GPU, MYRIAD\n",
    "        ie = IECore()\n",
    "\n",
    "        # Read IR\n",
    "        self.net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "\n",
    "        self.input_blob = next(iter(self.net.inputs))\n",
    "        self.out_blob = next(iter(self.net.outputs))\n",
    "        self.net.batch_size = 1\n",
    "\n",
    "        # Loading model to the plugin\n",
    "        self.exec_net = ie.load_network(network=self.net, device_name='CPU', num_requests=1)\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        start1 = time.time() #ここ追加\n",
    "\n",
    "        # Load from a file\n",
    "        image = Image.open(imageFile)\n",
    "\n",
    "        # Update orientation based on EXIF tags, if the file has orientation info.\n",
    "        image = super().update_orientation(image)\n",
    "\n",
    "        # Convert to OpenCV format\n",
    "        image = super().convert_to_opencv(image)\n",
    "\n",
    "        # If the image has either w or h greater than 1600 we resize it down respecting\n",
    "        # aspect ratio such that the largest dimension is 1600\n",
    "        image = super().resize_down_to_1600_max_dim(image)\n",
    "\n",
    "        # We next get the largest center square\n",
    "        h, w = image.shape[:2]\n",
    "        min_dim = min(w,h)\n",
    "        max_square_image = super().crop_center(image, min_dim, min_dim)\n",
    "\n",
    "        # Resize that square down to 256x256\n",
    "        augmented_image = super().resize_to_256_square(max_square_image)\n",
    "\n",
    "        # Get the input size of the model\n",
    "        n, c, h, w = self.net.inputs[self.input_blob].shape\n",
    "\n",
    "        # Crop the center for the specified network_input_Size\n",
    "        augmented_image = super().crop_center(augmented_image, w, h)\n",
    "        frame = augmented_image\n",
    "\n",
    "        #\n",
    "        augmented_image = augmented_image.transpose((2, 0, 1))\n",
    "\n",
    "        images = np.ndarray(shape=(n, c, h, w))\n",
    "        images[0] = augmented_image\n",
    "\n",
    "        start2 = time.time() #ここ追加\n",
    "        predictions = self.exec_net.infer(inputs={self.input_blob: images})\n",
    "        infer_time = time.time() - start2\n",
    "\n",
    "        # Print the highest probability label\n",
    "        predictions = predictions[self.out_blob]\n",
    "        highest_probability_index = predictions[0].argsort()[-1:][::-1][0]\n",
    "\n",
    "        total_time = time.time() - start1\n",
    "\n",
    "        return total_time, infer_time, self.labels[highest_probability_index], frame  #ここ追加\n",
    "\n",
    "\n",
    "def run_inference(modelFile, model_type=\"tf\", target_device='CPU', total=500):\n",
    "    if model_type == 'tf':\n",
    "        model = TFModel(modelFile)\n",
    "    elif model_type == 'tf_int8':\n",
    "        model = TFModel(modelFile)\n",
    "    else:\n",
    "        if target_device == 'GPU':\n",
    "            model = OpenVINOModel('GPU', modelFile)\n",
    "        elif target_device == 'MYRIAD':\n",
    "            model = OpenVINOModel('MYRIAD', modelFile)\n",
    "        else:\n",
    "            model = OpenVINOModel('CPU', modelFile)\n",
    "\n",
    "    total_infer_spent_time = 0\n",
    "    total_spent_time = 0\n",
    "    list_df = pd.DataFrame( columns=['正解ラベル','予測ラベル','全処理時間(msec)','推論時間(msec)'] )\n",
    "\n",
    "    match = 0\n",
    "    #file_list = glob.glob(os.path.join(dataset_dir, \"*\"))\n",
    "    file_list = glob.glob(\"train_data/test/*/*\")\n",
    "    for i in range(total):\n",
    "        img_path = random.choice(file_list)\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "        total_time, infer_time, pred_label, frame = model.predict(img_path)\n",
    "\n",
    "        if i > 1:\n",
    "            total_infer_spent_time += infer_time\n",
    "            total_spent_time += total_time\n",
    "\n",
    "        if img_cat == pred_label:\n",
    "            match = match + 1\n",
    "\n",
    "        print(img_path, str(int(total_time*1000.0)) + 'msec', str(int(infer_time*1000.0)) + 'msec', pred_label) #ここ追加\n",
    "\n",
    "        tmp_se = pd.Series( [img_cat, pred_label, str(int(total_time * 1000)), str(int(infer_time * 1000)) ], index=list_df.columns )\n",
    "        list_df = list_df.append( tmp_se, ignore_index=True ) \n",
    "\n",
    "    print()\n",
    "    print('全' + str(total) + '枚 完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / (total-1))*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / (total-1))*1000.0)) + \" ms/枚\")\n",
    "    print(\"正解率: \" + str(match / total * 100.0))\n",
    "    return int((total_spent_time / (total-1))*1000.0), int((total_infer_spent_time / (total-1))*1000.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_total_time, tf_infer_time = run_inference('saved_model.xml', model_type='openvino', total=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更に、IRをOpenVINOの推論エンジン（IE）上で実行してみます。TensorFlowの時と同じ推論スクリプトを使用します。モデルはFP32のままですが、IRに変換することでモデルの内部構造がCPUに最適化され、大きく性能が向上したことが確認できるかと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
