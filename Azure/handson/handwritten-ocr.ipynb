{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --list models.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging as log\n",
    "from argparse import ArgumentParser, SUPPRESS\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from openvino.inference_engine import IECore\n",
    "from utils.codec import CTCCodec\n",
    "\n",
    "import sys\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import IPython.display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "def build_argparser():\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    args = parser.add_argument_group('Options')\n",
    "    args.add_argument('-h', '--help', action='help', default=SUPPRESS,\n",
    "                      help='Show this help message and exit.')\n",
    "    args.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "                      help=\"Path to an .xml file with a trained model.\")\n",
    "    args.add_argument(\"-i\", \"--input\", type=str, required=True,\n",
    "                      help=\"Required. Path to an image to infer\")\n",
    "    args.add_argument(\"-d\", \"--device\", type=str, default=\"CPU\",\n",
    "                      help=\"Optional. Specify the target device to infer on; CPU, GPU, FPGA, HDDL, MYRIAD or HETERO: is \"\n",
    "                           \"acceptable. The sample will look for a suitable plugin for device specified. Default \"\n",
    "                           \"value is CPU\")\n",
    "    args.add_argument(\"-ni\", \"--number_iter\", type=int, default=1,\n",
    "                      help=\"Optional. Number of inference iterations\")\n",
    "    args.add_argument(\"-cl\", \"--charlist\", type=str, default=os.path.join(os.path.dirname(__file__), \"data/kondate_nakayosi_char_list.txt\"), help=\"Path to the decoding char list file\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "def get_characters():\n",
    "    '''Get characters'''\n",
    "    charlist = \"data/kondate_nakayosi_char_list.txt\"\n",
    "    with open(charlist, 'r', encoding='utf-8') as f:\n",
    "        return ''.join(line.strip('\\n') for line in f)\n",
    "\n",
    "\n",
    "def preprocess_input(image_name, height, width):\n",
    "    src = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "    ratio = float(src.shape[1]) / float(src.shape[0])\n",
    "    tw = int(height * ratio)\n",
    "    rsz = cv2.resize(src, (tw, height), interpolation=cv2.INTER_AREA).astype(np.float32)\n",
    "    # [h,w] -> [c,h,w]\n",
    "    img = rsz[None, :, :]\n",
    "    _, h, w = img.shape\n",
    "    # right edge padding\n",
    "    pad_img = np.pad(img, ((0, 0), (0, height - h), (0, width -  w)), mode='edge')\n",
    "    return pad_img\n",
    "\n",
    "\n",
    "def main(image_path):\n",
    "    log.basicConfig(format=\"[ %(levelname)s ] %(message)s\", level=log.INFO, stream=sys.stdout)\n",
    "#    args = build_argparser().parse_args()\n",
    "\n",
    "    # Plugin initialization\n",
    "    ie = IECore()\n",
    "    # Read IR\n",
    "    log.info(\"Loading network\")\n",
    "    model = \"intel/handwritten-japanese-recognition-0001/FP32/handwritten-japanese-recognition-0001.xml\"\n",
    "    net = ie.read_network(model, os.path.splitext(model)[0] + \".bin\")\n",
    "\n",
    "    assert len(net.inputs) == 1, \"Demo supports only single input topologies\"\n",
    "    assert len(net.outputs) == 1, \"Demo supports only single output topologies\"\n",
    "\n",
    "    log.info(\"Preparing input/output blobs\")\n",
    "    input_blob = next(iter(net.inputs))\n",
    "    out_blob = next(iter(net.outputs))\n",
    "\n",
    "    characters = get_characters()\n",
    "    codec = CTCCodec(characters)\n",
    "    assert len(codec.characters) == net.outputs[out_blob].shape[2], \"The text recognition model does not correspond to decoding character list\"\n",
    "\n",
    "    input_batch_size, input_channel, input_height, input_width= net.inputs[input_blob].shape\n",
    "\n",
    "    # Read and pre-process input image (NOTE: one image only)\n",
    "    input_path = image_path\n",
    "    input_image = preprocess_input(input_path, height=input_height, width=input_width)[None,:,:,:]\n",
    "    assert input_batch_size == input_image.shape[0], \"The net's input batch size should equal the input image's batch size \"\n",
    "    assert input_channel == input_image.shape[1], \"The net's input channel should equal the input image's channel\"\n",
    "\n",
    "    # Loading model to the plugin\n",
    "    log.info(\"Loading model to the plugin\")\n",
    "    exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "    # Start sync inference\n",
    "    number_iter = 1\n",
    "    log.info(\"Starting inference ({} iterations)\".format(number_iter))\n",
    "    infer_time = []\n",
    "    for i in range(number_iter):\n",
    "        img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(img).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "        \n",
    "        t0 = time.time()\n",
    "        preds = exec_net.infer(inputs={input_blob: input_image})\n",
    "        preds = preds[out_blob]\n",
    "        result = codec.decode(preds)\n",
    "        print(result)\n",
    "        infer_time.append((time.time() - t0) * 1000)\n",
    "\n",
    "    log.info(\"Average throughput: {} ms\".format(np.average(np.asarray(infer_time))))\n",
    "\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"data/test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"myname.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"intelkk.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"techc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"sentence.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
